{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import urllib.request as req\r\n",
    "import bs4\r\n",
    "import time\r\n",
    "import os\r\n",
    "from fake_useragent import UserAgent\r\n",
    "\r\n",
    "def get_img(url, title):\r\n",
    "\r\n",
    "    ua = UserAgent()\r\n",
    "    user_angent = ua.random\r\n",
    "\r\n",
    "    request = req.Request(url, headers={\r\n",
    "    \"User-Agent\":user_angent,\r\n",
    "    \"cookie\":\"over18=1\"\r\n",
    "    })\r\n",
    "\r\n",
    "    with req.urlopen(request) as response:\r\n",
    "        data = response.read().decode(\"utf-8\")\r\n",
    "\r\n",
    "    root = bs4.BeautifulSoup(data, \"html.parser\")\r\n",
    "    imgs = root.find_all(\"a\", target = \"_blank\")\r\n",
    "\r\n",
    "    index = 0\r\n",
    "    sleep_time = 0\r\n",
    "    for img in imgs:\r\n",
    "        # print(img[\"href\"]) # Get Link\r\n",
    "        if((\"html\") not in img[\"href\"]):\r\n",
    "            if(\"twimg\" in img[\"href\"] or \"imgur\" in img[\"href\"]):\r\n",
    "                if(\"jpg\" in img[\"href\"] or \"png\" in img[\"href\"] or \"gif\" in img[\"href\"]):\r\n",
    "                    img_link = img[\"href\"]\r\n",
    "                else:\r\n",
    "                    img_link = img[\"href\"] + \".jpg\"\r\n",
    "            else:\r\n",
    "                continue\r\n",
    "        else:\r\n",
    "            continue\r\n",
    "\r\n",
    "        if not os.path.exists(title): # check file address\r\n",
    "            os.mkdir(title)\r\n",
    "\r\n",
    "        # print(os.path.abspath(title))\r\n",
    "        if(sleep_time == 5): # prevent error 429\r\n",
    "            print(\"sleep 5 sec\")\r\n",
    "            time.sleep(5)\r\n",
    "            sleep_time = 0\r\n",
    "            print(\"sleep end\")\r\n",
    "\r\n",
    "        user_angent = ua.random\r\n",
    "        # print(user_angent)\r\n",
    "        request = req.Request(url, headers={\r\n",
    "        \"User-Agent\":user_angent,\r\n",
    "        \"cookie\":\"over18=1\"\r\n",
    "        })\r\n",
    "        req.urlretrieve(img_link, os.path.abspath(title) + r\"/\" + str(index+1) + img_link[-4:])\r\n",
    "        index = index + 1\r\n",
    "        sleep_time = sleep_time + 1\r\n",
    "\r\n",
    "\r\n",
    "def get_data(url):\r\n",
    "\r\n",
    "    ua = UserAgent()\r\n",
    "    user_angent = ua.random\r\n",
    "\r\n",
    "    # Set User-agent like we are user\r\n",
    "    request = req.Request(url, headers={\r\n",
    "        \"User-Agent\":user_angent,\r\n",
    "        \"cookie\":\"over18=1\"\r\n",
    "    })\r\n",
    "\r\n",
    "    with req.urlopen(request) as response:\r\n",
    "        data = response.read().decode(\"utf-8\")\r\n",
    "    #print(data)\r\n",
    "    \r\n",
    "    # Decode\r\n",
    "    root = bs4.BeautifulSoup(data, \"html.parser\")\r\n",
    "    titles = root.find_all(\"div\", class_=\"title\")\r\n",
    "\r\n",
    "    for title in titles:\r\n",
    "        if (title.a != None) and ((\"肉特\") not in title.a.string) and ((\"大尺碼\")not in title.a.string) and(((\"正妹\") or (\"神人\")) in title.a.string)and((\"Re\") not in title.a.string):\r\n",
    "            # print(title.a)\r\n",
    "            print(title.a.string)\r\n",
    "\r\n",
    "            title_ = title.a.string\r\n",
    "            title_ = title_.replace(\"/\", \"_\")\r\n",
    "\r\n",
    "            artical_url = \"https://www.ptt.cc\" + title.a[\"href\"]\r\n",
    "            #print(artical_url)\r\n",
    "            print(\"Downloading\")\r\n",
    "            get_img(artical_url, title_)\r\n",
    "            print(\"Downloading success\")\r\n",
    "\r\n",
    "    print(\"Next Page\")\r\n",
    "    nextLink = root.find(\"a\", string= \"‹ 上頁\") # get 上頁 address\r\n",
    "    # print(nextLink)\r\n",
    "    # print(nextLink[\"href\"])\r\n",
    "    return(nextLink[\"href\"])\r\n",
    "\r\n",
    "Page_url = \"https://www.ptt.cc/bbs/Beauty/index.html\"\r\n",
    "count = int(input(\"Input how many page you want to crawler\"))\r\n",
    "while count > 0:\r\n",
    "    Page_url = \"https://www.ptt.cc\" + get_data(Page_url)\r\n",
    "    count = count - 1"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('Python_38': conda)"
  },
  "interpreter": {
   "hash": "a600b8b310a4ab207ddf1e6ab9f6f2d91f625e42330638e53390e6a988177dea"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}