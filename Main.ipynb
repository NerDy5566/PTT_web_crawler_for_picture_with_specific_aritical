{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import urllib.request as req\r\n",
    "import bs4\r\n",
    "# import requests\r\n",
    "import os\r\n",
    "\r\n",
    "def get_img(url, title):\r\n",
    "    request = req.Request(url, headers={\r\n",
    "    \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\",\r\n",
    "    \"cookie\":\"over18=1\"\r\n",
    "    })\r\n",
    "\r\n",
    "    with req.urlopen(request) as response:\r\n",
    "        data = response.read().decode(\"utf-8\")\r\n",
    "\r\n",
    "    root = bs4.BeautifulSoup(data, \"html.parser\")\r\n",
    "    imgs = root.find_all(\"a\", target = \"_blank\")\r\n",
    "\r\n",
    "    index = 0\r\n",
    "    for img in imgs:\r\n",
    "        # print(img[\"href\"]) # Get Link\r\n",
    "        if( (\"html\") not in img[\"href\"]):\r\n",
    "            img_link = img[\"href\"]\r\n",
    "\r\n",
    "        if not os.path.exists(title): # check file address\r\n",
    "            os.mkdir(title)\r\n",
    "\r\n",
    "        # print(os.path.abspath(title))\r\n",
    "        req.urlretrieve(img_link, os.path.abspath(title) + r\"/\" + str(index+1) + img_link[-4:])\r\n",
    "        index = index + 1\r\n",
    "\r\n",
    "\r\n",
    "def get_data(url):\r\n",
    "    # Get website source code(HTML)\r\n",
    "    import urllib.request as req\r\n",
    "\r\n",
    "    # Set User-agent like we are user\r\n",
    "    request = req.Request(url, headers={\r\n",
    "        \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\",\r\n",
    "        \"cookie\":\"over18=1\"\r\n",
    "    })\r\n",
    "\r\n",
    "    with req.urlopen(request) as response:\r\n",
    "        data = response.read().decode(\"utf-8\")\r\n",
    "    #print(data)\r\n",
    "    \r\n",
    "    # Decode\r\n",
    "    root = bs4.BeautifulSoup(data, \"html.parser\")\r\n",
    "    titles = root.find_all(\"div\", class_=\"title\")\r\n",
    "\r\n",
    "    for title in titles:\r\n",
    "        if (title.a != None)and((\"肉特\") not in title.a.string)and((\"公告\") not in title.a.string)and((\"Re\") not in title.a.string):\r\n",
    "            # print(title.a)\r\n",
    "            print(title.a.string)\r\n",
    "            artical_url = \"https://www.ptt.cc\" + title.a[\"href\"]\r\n",
    "            #print(artical_url)\r\n",
    "            print(\"Downloading\")\r\n",
    "            get_img(artical_url, title.a.string)\r\n",
    "            print(\"Downloading success\")\r\n",
    "\r\n",
    "    print(\"Next Page\")\r\n",
    "    nextLink = root.find(\"a\", string= \"‹ 上頁\") # get 上頁 address\r\n",
    "    # print(nextLink)\r\n",
    "    # print(nextLink[\"href\"])\r\n",
    "    return(nextLink[\"href\"])\r\n",
    "\r\n",
    "Page_url = \"https://www.ptt.cc/bbs/Beauty/index.html\"\r\n",
    "count = 0\r\n",
    "while count<5:\r\n",
    "    Page_url = \"https://www.ptt.cc\" + get_data(Page_url)\r\n",
    "    count = count + 1"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('Python_38': conda)"
  },
  "interpreter": {
   "hash": "a600b8b310a4ab207ddf1e6ab9f6f2d91f625e42330638e53390e6a988177dea"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}